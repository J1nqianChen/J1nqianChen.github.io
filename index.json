
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"About me\nI am currently a Ph.D. student in Xi’an Jiaotong University under the supervision of Prof. Jihua Zhu. I have also received the Bachelor degree of software engineering at Xi’an Jiaotong University in 2021.\nMy research area mainly focuses on machine learning, with special interests in federated learning, uncertainty estimation and point cloud processing.\nResearch Interests\nFederated Learning Uncertainty Estimation Multimodal Point Cloud News\n2023/07/26: Our paper “Towards Fast and Stable Federated Learning: Confronting Heterogeneity via Knowledge Anchor” has been accepted by ACM Multimedia 2023 (CCF-A, First Author). 2023/12/19: Our Paper “Watch your Head: Assembling Projection Heads to Save the Reliability of Federated Models” has been accepted by AAAI-24 (CCF-A, First Author). 2024/05/16: Our paper “Breaking Barriers of System Heterogeneity: Straggler-Tolerant Multimodal Federated Learning via Knowledge Distillation” has been accepted by IJCAI-24 (CCF-A, First Author). ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"About me\nI am currently a Ph.D. student in Xi’an Jiaotong University under the supervision of Prof. Jihua Zhu. I have also received the Bachelor degree of software engineering at Xi’an Jiaotong University in 2021.","tags":null,"title":"Jinqian Chen","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://J1nqianChen.github.io/talk/example-talk.html","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk.html","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["**Jinqian Chen**","Haoyu Tang","Junhao Cheng","Ming Yan","Ji Zhang","Mingzhu Xu","Yupeng Hu","Liqiang Nie"],"categories":null,"content":"","date":1716681600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1716681600,"objectID":"fdbb5073640f1d04b5fbb487f9c7a66d","permalink":"https://J1nqianChen.github.io/publication/2024-mflakd.html","publishdate":"2024-05-26T00:00:00Z","relpermalink":"/publication/2024-mflakd.html","section":"publication","summary":"Internet of Things (IoT) devices possess valuable but high-risk data in various modalities, calling for the multimodal decentralized machine learning schema. Though several multimodal federated learning (MFL) methods have been proposed, most of them naively overlook the system heterogeneity across IoT devices, resulting in the inadaptability to real world applications. Aiming at this, we conduct extensive experiments in real world scenarios and uncover the significant fact that stragglers caused by system heterogeneity is fatal to MFL, resulting in the catastrophic time overhead. Motivated by this, we propose a novel Multimodal Federated Learning with Accelerated Knowledge Distillation (MFL-AKD) framework, which is the first attempt to integrate knowledge distillation to combat stragglers in complex multimodal federated scenarios. Concretely, given the pretrained large-scale vision-language models deployed in the central server, we apply a quick knowledge transfer strategy before full batch updating in all clients. Extensive evaluations have been conducted on two datasets for video moment retrieval and two datasets for text-image retrieval, and the results demonstrate that our proposed framework achieves significant time gain while maintaining high accuracy.","tags":null,"title":"Breaking Barriers of System Heterogeneity: Straggler-Tolerant Multimodal Federated Learning via Knowledge Distillation","type":"publication"},{"authors":null,"categories":null,"content":"Nothing. ","date":1716681600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1716681600,"objectID":"ae300ac2b63d15290cd488d84d7c0326","permalink":"https://J1nqianChen.github.io/news/ijcai24-accept.html","publishdate":"2024-05-26T00:00:00Z","relpermalink":"/news/ijcai24-accept.html","section":"news","summary":"Paper: Breaking Barriers of System Heterogeneity: Straggler-Tolerant Multimodal Federated Learning via Knowledge Distillation is accepted by IJCAI-2024.","tags":["Publication"],"title":"One paper is accepted by IJCAI-2024 (CCF-A).","type":"news"},{"authors":["**Jinqian Chen**","Jihua Zhu","Qinghai Zheng","Zhiqiang Tian","Zhongyu Li"],"categories":null,"content":"","date":1706227200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706227200,"objectID":"18c83c10b03ac4169e3b07d65e190943","permalink":"https://J1nqianChen.github.io/publication/2024-aph.html","publishdate":"2024-01-26T00:00:00Z","relpermalink":"/publication/2024-aph.html","section":"publication","summary":"Federated learning encounters substantial challenges with heterogeneous data, leading to performance degradation and convergence issues. While considerable progress has been achieved in mitigating such an impact, the reliability aspect of federated models has been largely disregarded. In this study, we conduct extensive experiments to investigate the reliability of both generic and personalized federated models. Our exploration uncovers a significant finding: federated models exhibit unreliability when faced with heterogeneous data, demonstrating poor calibration on in-distribution test data and low uncertainty levels on out-of-distribution data. This unreliability is primarily attributed to the presence of biased projection heads, which introduce miscalibration into the federated models. Inspired by this observation, we propose the Assembled Projection Heads (APH) method for enhancing the reliability of federated models. By treating the existing projection head parameters as priors, APH randomly samples multiple initialized parameters of projection heads from the prior and further performs targeted fine-tuning on locally available data under varying learning rates. Such a head ensemble introduces parameter diversity into the deterministic model, eliminating the bias and producing reliable predictions via head averaging. We evaluate the effectiveness of the proposed APH method across three prominent federated benchmarks. Experimental results validate the efficacy of APH in model calibration and uncertainty estimation. Notably, APH can be seamlessly integrated into various federated approaches but only requires less than 30% additional computation cost for 100× inferences within large models.","tags":null,"title":"Watch Your Head: Assembling Projection Heads to Save the Reliability of Federated Models","type":"publication"},{"authors":null,"categories":null,"content":"Nothing. ","date":1703548800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1703548800,"objectID":"ee94e7e3cdd87bf28083fcd79cb42ac6","permalink":"https://J1nqianChen.github.io/news/aaai24-accept.html","publishdate":"2023-12-26T00:00:00Z","relpermalink":"/news/aaai24-accept.html","section":"news","summary":"Paper: Watch Your Head: Assembling Projection Heads to Save the Reliability of Federated Models is accepted by AAAI 2024 (CCF-A).","tags":["Publication"],"title":"One paper is accepted by AAAI 2024 (CCF-A)","type":"news"},{"authors":null,"categories":null,"content":"Nothing. ","date":1690329600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690329600,"objectID":"6cfb047f0a85e4f8bcea2d94b941231f","permalink":"https://J1nqianChen.github.io/news/mm-accept.html","publishdate":"2023-07-26T00:00:00Z","relpermalink":"/news/mm-accept.html","section":"news","summary":"Paper: Towards Fast and Stable Federated Learning: Confronting Heterogeneity via Knowledge Anchor is accepted by ACM Multimedia 2023.","tags":["Publication"],"title":"One paper is accepted by ACM Multimedia 2023 (CCF-A)","type":"news"},{"authors":["**Jinqian Chen**","Jihua Zhu","Qinghai Zheng"],"categories":null,"content":"","date":1690329600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690329600,"objectID":"3e379a408368d32eaa199175f2f86752","permalink":"https://J1nqianChen.github.io/publication/2023-fedka.html","publishdate":"2023-07-26T00:00:00Z","relpermalink":"/publication/2023-fedka.html","section":"publication","summary":"Federated learning encounters a critical challenge of data heterogeneity, adversely affecting the performance and convergence of the federated model. Various approaches have been proposed to address this issue, yet their effectiveness is still limited. Recent studies have revealed that the federated model suffers severe forgetting in local training, leading to global forgetting and performance degradation. Although the analysis provides valuable insights, a comprehensive understanding of the vulnerable classes and their impact factors is yet to be established. In this paper, we aim to bridge this gap by systematically analyzing the forgetting degree of each class during local training across different communication rounds. Our observations are: (1) Both missing and non-dominant classes suffer similar severe forgetting during local training, while dominant classes show improvement in performance. (2) When dynamically reducing the sample size of a dominant class, catastrophic forgetting occurs abruptly when the proportion of its samples is below a certain threshold, indicating that the local model struggles to leverage a few samples of a specific class effectively to prevent forgetting. Motivated by these findings, we propose a novel and straightforward algorithm called Federated Knowledge Anchor (FedKA). Assuming that all clients have a single shared sample for each class, the knowledge anchor is constructed before each local training stage by extracting shared samples for missing classes and randomly selecting one sample per class for non-dominant classes. The knowledge anchor is then utilized to correct the gradient of each mini-batch towards the direction of preserving the knowledge of the missing and non-dominant classes. Extensive experimental results demonstrate that our proposed FedKA achieves fast and stable convergence, significantly improving accuracy on popular benchmarks","tags":null,"title":"Towards Fast and Stable Federated Learning: Confronting Heterogeneity via Knowledge Anchor","type":"publication"},{"authors":null,"categories":null,"content":"Update will be posted here.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"006f6f30ba9f03341dfbc41d9d1dd847","permalink":"https://J1nqianChen.github.io/project/hybrid-nanoporous-materials.html","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/hybrid-nanoporous-materials.html","section":"project","summary":"Ongoing MSCA project","tags":["Nanofluids"],"title":"Hybrid nanoporous materials for the separation of fluid mixtures","type":"project"}]